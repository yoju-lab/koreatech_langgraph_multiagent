{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ba51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "search_tool.invoke(\"LangGraph가 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01910fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool\n",
    "def human_assist(query):\n",
    "    \"\"\"Human assist tool\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf248ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=openai_model)\n",
    "tools = [search_tool, human_assist]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcefd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "tool_node = ToolNode(tools)\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"chatbot\", chatbot)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"chatbot\")\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de063f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21280d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8761b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "snapshot = graph.get_state(config)\n",
    "if 'messages' in snapshot.values:\n",
    "    pprint(snapshot.values['messages'])\n",
    "else:\n",
    "    print(\"No messages found in the snapshot.\")\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32032d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input1 = \"AI 에이전트 개발을 위한 LangGraph의 특징에 대해 설명해주세요.\"\n",
    "state1 = {\"messages\": [HumanMessage(content=user_input1)]}\n",
    "response1 = graph.invoke(state1, config)\n",
    "print(response1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "if 'messages' in snapshot.values:\n",
    "    pprint(snapshot.values['messages'])\n",
    "else:\n",
    "    print(\"No messages found in the snapshot.\")\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7587e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input2 = \"AI 에이전트 개발을 위한 기술 선택에 대한 전문가의 지원이 필요해요. 지원 요청을 해도 될까요?\"\n",
    "state2 = {\"messages\": [HumanMessage(content=user_input2)]}\n",
    "response2 = graph.invoke(state2, config)\n",
    "print(response2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a06569",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "if 'messages' in snapshot.values:\n",
    "    pprint(snapshot.values['messages'])\n",
    "else:\n",
    "    print(\"No messages found in the snapshot.\")\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60740350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "human_response = (\n",
    "    \"네, 물론입니다. AI 에이전트 개발을 위한 기술 선택에 대한 지원을 해드리겠습니다. \"\n",
    "    \"우선 LangGraph를 사용하는 것에 대해 어떻게 생각하시나요? \"\n",
    "    \"LangGraph는 AI 에이전트를 개발하는 데 매우 유용한 도구입니다. \"\n",
    ")\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "response = graph.invoke(human_command, config)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "pprint(snapshot.values['messages'])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaabc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input3 = \"앞서 추천해주신 기술의 시장성은 어떤가요?\"\n",
    "state3 = {\"messages\": [HumanMessage(content=user_input3)]}\n",
    "response3 = graph.invoke(state3, config)\n",
    "print(response3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73827854",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "pprint(snapshot.values['messages'])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input4 = \"LangGraph의 메모리 기능 추가에 대한 전문가의 지원이 필요해요.\"\n",
    "state4 = {\"messages\": [HumanMessage(content=user_input4)]}\n",
    "response4 = graph.invoke(state4, config)\n",
    "print(response4[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee228ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "if 'messages' in snapshot.values:\n",
    "    pprint(snapshot.values['messages'])\n",
    "else:\n",
    "    print(\"No messages found in the snapshot.\")\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_response = (\n",
    "    \"MemorySaver는 메모리 기반의 체크포인터로, 각 대화의 상태를 메모리에 임시로 저장하고 관리합니다. \"\n",
    "    \"이를 통해 챗봇은 이전 대화 내용을 기억하고 다음 번 상호작용 시에도 맥락을 유지한 상태로 대화를 진행할 수 있습니다. \"\n",
    "    \"실제 운영 환경에서는 더 영구적인 상태 관리를 위해 데이터베이스 기반 체크포인터(예: SqliteSaver 또는 PostgresSaver)를 사용하는 것이 권장됩니다.\"\n",
    ")\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "response = graph.invoke(human_command, config)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e78da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "pprint(snapshot.values['messages'])\n",
    "print(snapshot.next)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
