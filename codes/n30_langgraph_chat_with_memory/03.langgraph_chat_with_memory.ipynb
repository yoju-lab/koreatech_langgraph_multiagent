{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ace46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tool.invoke(\"LangGraph가 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d08f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98505728",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=openai_model)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a72331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aff27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6320fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "tool_node = ToolNode(tools)\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"chatbot\", chatbot)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"chatbot\")\n",
    "workflow.set_entry_point(\"chatbot\")\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c68f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ca0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef274e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 대화: 새로운 대화 맥락 생성\n",
    "user_input1 = \"LangGraph가 무엇인가요?\"\n",
    "state1 = {\"messages\": [HumanMessage(content=user_input1)]}\n",
    "response1 = graph.invoke(state1, config)\n",
    "# 챗봇의 첫 번째 응답 출력\n",
    "print(response1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3246de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 대화: 이전 대화 맥락 유지\n",
    "user_input2 = \"그것을 만든 회사는 어딘가요?\"\n",
    "state2 = {\"messages\": [HumanMessage(content=user_input2)]}\n",
    "response2 = graph.invoke(state2, config)\n",
    "# 챗봇의 두 번째 응답 출력 (이전 대화의 맥락이 유지된 상태)\n",
    "print(response2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 번째 대화: 새로운 thread_id 사용하여 독립된 새로운 대화 맥락 생성\n",
    "user_input3 = \"그것을 만든 회사는 어딘가요?\"\n",
    "state3 = {\"messages\": [HumanMessage(content=user_input3)]}\n",
    "response3 = graph.invoke(state3, {\"configurable\": {\"thread_id\": \"user456\"}})\n",
    "# 새로운 대화 맥락에서의 챗봇 응답 출력 (기존 thread_id와 독립된 상태)\n",
    "print(response3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db99cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 thread_id의 대화 상태 확인\n",
    "snapshot = graph.get_state(config)\n",
    "snapshot.values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 thread_id의 대화 상태 확인\n",
    "graph.get_state({\"configurable\": {\"thread_id\": \"user456\"}}).values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5858185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# 체크포인터가 MemorySaver일 경우 예시\n",
    "all_snapshots = memory.list({})  # 모든 thread_id 상태 조회\n",
    "for snapshot in all_snapshots:\n",
    "    print(snapshot.config['configurable']['thread_id'])\n",
    "    if 'messages' in snapshot.checkpoint['channel_values']:\n",
    "        pprint(snapshot.checkpoint['channel_values']['messages'])\n",
    "    else:\n",
    "        print(\"No messages found in this snapshot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
